---
title: "ANALISI DATASET neuroblastoma"
output: html_notebook
---

ANALISI DATASET neuroblastoma.csv

Algoritmo di clustering: K-means

Iperparametri:

-   k=2

-   k=3

-   k=5

```{r}
library(UniversalCVI)
library(readr)
library(fpc)

# Lettura e pulizia del dataset da dati NA
dataset <- na.omit(read.csv("~/Calinski_Harabasz_Thesis/Data/DatasetReali/10_7717_peerj_5665_dataYM2018_neuroblastoma.csv"))

# Creazione lista con i valori di k
k <- c(2,3,5)

# Clustering con K-means e validazione del clustering con CH.IDX
df <- CH.IDX(dataset, 5)
for (i in k) {
  
  # Stampa risultati
  cat(sprintf("\nIndice Calinski-Harabasz per k=%i: %f\n",i, df[i-1,2] ))

}

# Calcolo con la funzione calinhara di fpc l'indice di Calinski-Harabasz
# Per verificare che corrispona ai valori ottenuti con CH.IDX
for (i in k) {
  cl <- kmeans(dataset, i, , 100)
  print(calinhara(dataset, cl$cluster))
}
 



```

Quindi verifichiamo che applicando l'algoritmo di clustering K-means, la metrica di Calinski-Harabasz individua come miglior configurazione quella con il valore di k=5 rispetto a quelle scelte.

------------------------------------------------------------------------

Algoritmo di clustering: DBSCAN

Iperparametri:

-   𝜀=5 , minPts=14

-   𝜀=6 , minPts=14 

-   𝜀=5 , minPts=16 

```{r}
library(dbscan)

# Creazione dataframe iterazioni/valore
risultati <- data.frame(caso = integer(), valore = numeric(),
                        stringsAsFactors = FALSE)

# Creazione lista con i valori di eps
list_eps <- c(3, 3.5, 3)

# Creazione lista con i valori di minPts
list_minPts <- c(10, 10, 11)

# Controllo lunghezza liste
if(length(list_eps)==length(list_minPts)){
  
  # Ciclo per la validazione del clustering
  for (i in 1:length(list_eps)) { 
    eps <- list_eps[i]          #estrae il valore di eps
    minPts <- list_minPts[i]    #estrae il valore di minPts
    
    # Clustering con DBSCAN 
    clustering <- dbscan(dataset, eps, minPts)
    
    # Aggiornamento dataframe coi risultati
    risultati <- rbind(risultati, data.frame(caso=i, valore=calinhara(dataset, clustering$cluster)))
    
    # Stampa risultato
    cat(sprintf("\nIndice Calinski-Harabasz per eps=%g e minPts=%g: %f\n",eps , minPts, risultati[i,2] ))
  }
} else {
  print("Le liste devono avere la stessa lunghezza")  
}


```

Quindi verifichiamo che applicando l'algoritmo di clustering DBSCAN, la metrica di Calinski-Harabasz individua come miglior configurazione quella con i valori di 𝜀=?? e minPts=??  rispetto a quelle scelte.

------------------------------------------------------------------------

Algoritmo di clustering: Hierarchical clustering

Iperparametri:

-   complete-linkage

-   average-linkage

-   single-linkage

```{r}

# Clustering con complete-linkage e validazione del clustering con CH.IDX
cmplt_link <- CH.IDX(dataset, 10, 2, "hclust_complete")

# Stampa risultati
cat(sprintf("\nIndice Calinski-Harabasz per complete-linkage: \n"))
print(cmplt_link)

# Clustering con average-linkage e validazione del clustering con CH.IDX
avrg_link <- CH.IDX(dataset, 10, 2, "hclust_average")

# Stampa risultati
cat(sprintf("\nIndice Calinski-Harabasz per average-linkage: \n"))
avrg_link

# Clustering con single-linkage e validazione del clustering con CH.IDX
sngl_link <- CH.IDX(dataset, 10, 2, "hclust_single")

# Stampa risultati
cat(sprintf("\nIndice Calinski-Harabasz per single-linkage: \n"))
sngl_link
```

Quindi verifichiamo che applicando l'algoritmo di clustering Hierarchical clustering, la metrica di Calinski-Harabasz individua come miglior configurazione quella con tipo complete-linkage rispetto alle altre opzioni.

CONCLUSIONI:

L'analisi effettuata tramite la metrica di Calinski-Harabasz indica come miglior risultato la combinazione di ?? come algoritmo di clustering con configurazione di iperparametri ?? .
